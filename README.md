# Medical RAG Assistant â€” Case Study (Public)

> **Status:** Case-study repo (readme + assets). **Full source is private** to protect IP and dataset licenses. For access, please contact: **\[your email]**.

---

## 1) Oneâ€‘line value

An AI assistant that answers medical questions with **Retrievalâ€‘Augmented Generation (RAG)**, optimized for **evidenceâ€‘grounded**, **lowâ€‘hallucination** responses.

* **Domain:** Medical (clinical/biomedical literature)
* **Stack:** LangChain â€¢ **MedEmbed-large-v0.1** (HF embeddings) â€¢ **Cross-Encoder/ms-marco-MiniLM-L12-v2** (reranker) â€¢ **FAISS / Qdrant / Milvus** â€¢ Python â€¢ Streamlit/Flask â€¢ **OpenAI GPTâ€‘4.1** (primary) â€¢ **Groq Llamaâ€‘3â€‘8Bâ€‘8192** (fallback/speed)
* **Dataset for eval:** **LitQA v2** (heldâ€‘out **49** unseen questions)

---

## 2) Demo & screenshots

* **Short demo video:** *add link*
* **Screenshots:** `/assets/` (home, ask flow, sources panel, failure cases)
* **Live demo (optional):** *add link*

> Demo excludes any restricted/paid datasets and PHI/PII.

---

## 3) Problem & context

LLMs hallucinateâ€”dangerous in medical QA. We specialize a RAG pipeline to the **medical domain**, forcing **evidenceâ€‘grounded** answers with a transparent sources panel, while improving **retrieval quality, latency, and evaluation fairness**.

---

## 4) Contributions vs. PaperHelper

* **Domain embeddings:** swap generic embeddings for **MedEmbedâ€‘largeâ€‘v0.1** (biomedical).
* **Hybrid retrieval:** **dense (FAISS/Milvus/Qdrant) + BM25** rather than vectorâ€‘only.
* **Twoâ€‘step ranking:** **Reciprocal Rank Fusion (RRF)** â†’ **crossâ€‘encoder/msâ€‘marcoâ€‘MiniLMâ€‘L12â€‘v2**.
* **Context optimizer:** **topâ€‘3 sentence** compression, **semantic dedup**, tokenizerâ€‘aware truncation.
* **Evaluation:** **LitQA v2** with tolerant scoring for typos/abbreviations; F1/EM/latency/tokens.
* **LLM routing:** **OpenAI GPTâ€‘4.1** for accuracy, **Groq Llamaâ€‘3â€‘8Bâ€‘8192** for speed.

---

## 5) System architecture

```
[User UI]
   â†“
[Query preprocessor]
   â†“
[Hybrid retrieval]  <â€”  [Dense store: FAISS | Qdrant | Milvus] + [BM25]
   â†“                 [Embeddings: MedEmbedâ€‘largeâ€‘v0.1]
[RRF fuse] â†’ [Crossâ€‘encoder rerank]
   â†“
[LLM Orchestrator]
   â†™             â†˜
[OpenAI GPTâ€‘4.1]  [Groq Llamaâ€‘3â€‘8Bâ€‘8192]
   â†“
[Grounded answer + sources panel]
```

**Key choices**

* **Chunking:** recursive character splitting (\~**450** chars, small overlap).
* **Basic RAG retrieval fanâ€‘out:** `k_dense=8`, `k_bm25=32`, final rerank `k=12`.
* **RAG Fusion:** generate **6** subâ€‘queries; fuse **topâ€‘3**; perâ€‘hit compression **top\_n=3**, **max\_chars=400**; crossâ€‘encoder keepâ‰ˆ**15**; semantic deâ€‘dup to â‰ˆ**10** unique chunks.
* **Token safety:** truncate context to fit LLM window (â‰ˆ**7,500** tokens for Llamaâ€‘3â€‘8B).

---

## 6) Features

* ðŸ“š Evidenceâ€‘grounded answers with a 'Sources used' panel
* ðŸ”Ž Hybrid retrieval + RRF fusion + crossâ€‘encoder rerank
* âœ‚ï¸ Context compression & semantic dedup â†’ lower tokens, higher precision
* ðŸ’¬ Model routing (OpenAI â†” Groq) for accuracy/speed tradeâ€‘offs
* ðŸ§ª Fair evaluation harness (F1/EM, latency, token use, typo/subset tolerance)
* ðŸ§¯ Medical disclaimer & refusal on insufficient evidence

---

## 7) Dataset & data governance

* **Evaluation:** LitQA v2 (heldâ€‘out split).
* **Ingestion:** only licensed/public documents for demos; restricted sets remain private.
* **Privacy:** no PHI/PII stored; logs sanitized.
* **Public repo policy:** this is a **caseâ€‘study**â€”full source kept private.

---

## 8) Evaluation (LitQA v2, 49 heldâ€‘out)

### 8.1 Highlights

* **Best Basic RAG (FAISS + OpenAI):** **F1 72.7%**, **EM 63.3%**, **latency 8.98 s**; **fastest** variant **7.33 s** (FAISS + Groq).
* **Best RAG Fusion (FAISS + OpenAI):** **F1 68.1%**, **EM 57.1%**, **latency 12.90 s**.
* **Best Ensemble (Qdrant + OpenAI):** **F1 79.3%**, **EM 69.4%**; **fastest ensemble** **34.47 s** (FAISS + OpenAI).
* **Token efficiency:** **Milvus + OpenAI** used **\~Â½ tokens** vs FAISS in comparable settings.

### 8.2 Baselines vs. ours

| System                                    |  F1 (%)  |  EM (%)  | Latency (s) |
| ----------------------------------------- | :------: | :------: | :---------: |
| LitQA Baseline â€” Basic RAG                |   31.5   |   22.4   |     0.90    |
| LitQA Baseline â€” RAG Fusion               |   23.3   |   16.3   |     3.12    |
| LitQA Baseline â€” Ensemble                 |   34.7   |   24.5   |     5.97    |
| PaperHelper â€” RAG (GPTâ€‘4)                 |   53.1   |     â€”    |     5.70    |
| PaperHelper â€” RAG Fusion (GPTâ€‘4)          |   58.2   |     â€”    |     5.60    |
| **Our Best â€” Basic (FAISS + OpenAI)**     | **72.7** |   63.3   |     8.98    |
| **Our Best â€” Fusion (FAISS + OpenAI)**    | **68.1** |   57.1   |    12.90    |
| **Our Best â€” Ensemble (Qdrant + OpenAI)** | **79.3** | **69.4** |    34.56    |

> Summary: A wellâ€‘optimized **Basic RAG** beat Fusion on both **accuracy** and **latency** for this task; **Ensemble** gives SOTA F1 but is slower.

### 8.3 What moved the needle (ablations)

* **Hybrid > vectorâ€‘only:** BM25 + dense improved recall â†’ higher F1.
* **RRF + crossâ€‘encoder:** better ranking precision than singleâ€‘stage retrieval.
* **Compression & dedup:** fewer, cleaner tokens with stable accuracy.
* **Model choice:** OpenAI > Groq on accuracy; Groq wins some speed tests.

---

## 9) How to try (no public code)

* **Watch the demo video:** *add link here*
* **Screenshots:** see `/assets/`
* **Live demo:** available **on request** (to control API costs). Email me and Iâ€™ll enable temporary access.
* **Full source:** private; see Section 12 to request read-only access.

## 10) Risks, ethics, and limitations

* **Not a medical device**; educational/research only.
* **No patient advice**; always consult licensed professionals.
* **Limits:** canâ€™t parse figures/tables; Ensemble has high latency; hallucination risk not zero.

---

## 11) Roadmap

* Inline citation markers in UI (optional)
* Live **LLMâ€‘asâ€‘aâ€‘judge** selector for Ensemble
* Hybrid + learningâ€‘toâ€‘rank rerankers
* Multimodal ingestion (figures/tables)
* Distillation for lower latency/cost

---

## 12) Requesting the code

Email **\yi559668@gmail.com** with name, affiliation, intended use. Readâ€‘only review access can be granted on request.

---

## 13) Citation

```
@misc{medical_rag_assistant_2025,
  title  = {Medical RAG Assistant: Domainâ€‘specialized RAG for Medical QA},
  author = {Youssef Ismail and Contributors},
  year   = {2025},
  url    = {https://github.com/<you>/medical-rag-assistant-case-study}
}
```

---

## 14) License

Copyright (c) 2025 Youssef Ismail. **All Rights Reserved.**

Commercial use, redistribution, or code access requires written permission.
